{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"WATCH THIS DEMONSTRATION Louisa Muschal (Product Manager, IBM Hyper Protect Services - GTM) explains the value of IBM Hyper Protect Services for clients and the marketplace. Additional ways to watch: Seismic replay available for download. IBM Hyper Protect Services is a service family available in IBM Cloud and IBM Systems that achieves total data privacy assurance for the protection of valuable corporate assets and sensitive data. From a recent, IBM-sponsored Ponemon Institute Security study , the global average cost of a data breach is $4.35M USD \u2014 and this increases significantly for industries with regulatory concerns. The loss of customer trust had serious financial consequences for the companies studied, and lost business was the largest of four major cost categories that contributed to the total cost of a data breach. The same study also looked at cost mitigation factors that either helped reduce costs preventatively or in the aftermath of a breach. Extensive use of encryption, data loss prevention, threat intelligence sharing and integrating security into the software development process (DevSecOps) were all associated with lower-than-average data breach costs. Among these, encryption had the greatest impact, reducing breach costs by an average of $360,000. Regulatory compliance is another challenge when considering moving sensitive data to the cloud. Requirements can be complex, and penalties can be significant! For example, the Payment Card Industry Data Security Standard (PCI-DSS), fines can range from $5K to $100K USD monthly. Annual recertification averages $15K -$70K. For United States Health Insurance Portability and Accountability Act (HIPAA), fines can be as high as $16M USD. HIPAA Compliance has 250+ validation points and is a 6-month to 3-year process. More recently there have been several regional data privacy laws that have come into effect or are coming soon! For example, the EU\u2019s General Data Protection Regulation (GDPR), the US State of California Consumer Privacy Act, Canada\u2019s Personal Information Protection and Electronic Documents Act (PIPEDA). All these regulations either mandate encryption of data at rest and in transit as required or strongly encourage encryption as a technical measure to protect data. But what about the keys that are used to encrypt? Who has control of the keys? Imagine that you built a house with all the latest safety and security features to protect your loved ones, your valuable possessions and treasured family keepsakes. You have video surveillance, fireproof safes, the latest security system, 24x365 monitoring, a guard dog, and all the latest technology. It is a virtual fortress! Now, you wouldn\u2019t want to give a key to home to just anyone, would you? That could be your one point of vulnerability that you didn\u2019t anticipate or might not be able to control. Protecting sensitive data is vital to an enterprise\u2019s cloud data security, privacy and digital trust. As we enter a new normal period of accelerated digital transformation post-COVID, the vast number of organizations are now relying heavily on public and hybrid cloud services. And companies in highly regulated industries, now more than ever, find themselves needing cloud services that offer a greater level of protection and privacy. The data protection needs of organizations are driven by the concerns about protecting sensitive information, intellectual property, and meeting compliance and regulatory requirements. The dilemma for organizations is how do they independently retain ownership and control of their data while still driving innovation. The more sensitive the data, companies want to have complete authority over their valuable data and associated workloads, including no access to sensitive data for even their cloud providers i.e., they require technical assurance that cloud provider cannot access data rather than relying on operational assurance that cloud provider policies say they will not access data. This is where Confidential Computing capabilities can play a huge part. Per a Confidential Computing Consortium Research Study , the total addressable market (TAM) for Confidential Computing will reach over $50B USD by 2026! Over 75% of demand is driven by regulated industries like banking, finance, insurance, healthcare, life sciences, public sector, and defense in 2021. Awareness of the benefits of CC and willingness to invest in exploration is expected to double across key regulated industries through 2026. IBM\u2019s view of confidential computing is to assure data privacy in the cloud. With IBM Cloud, your data is yours. When using IBM\u2019s Confidential Computing capabilities, sensitive data isolated into a protected enclave during processing. The contents of the enclave, data being processed and techniques used to process it are only accessible to authorized code invisible to anything or anyone else including the operating system and cloud provider. IBM as the cloud provider cannot access this data. IBM cannot therefore provide access to third parties even if compelled to do so by external factors. For example, in the case of regulations or rulings like: The \"Schrems II\" Decision , which found the Privacy Shield mechanism for transferring data between the EU and US did not protect EU citizens from bulk surveillance by the US government. The US CLOUD Act , which that allows the US government to subpoena requested data stored on servers regardless of whether the data are stored in the U.S. or on foreign soil IBM cannot turn over customer data. Customers own the encryption keys and the encrypted data. Additional enablement resources Numerous other learning paths and resources are available for IBM sellers and business partners. IBM Technology Zone : Use the Unified Key Orchestrator (UKO) to orchestrate keys across AWS and/or Azure IBM HPCS (Encryption) Seismic Sales Kit IBM HPVS (Confidential Compute & Digital Assets) Seismic Sales Kit Use these assets to bolster your skills and delight clients. Next steps As part of the hands-on experience of this Level 3 curriculum, you will learn how IBM Hyper Protect Services are helping to protect data with technical assurance to reduce the risk of a data breach, enhances data privacy and sovereignity, and protects what is most valuable to IBM clients with the speed, ease, and efficieny of cloud-native solutions.","title":"Introduction"},{"location":"#_1","text":"","title":""},{"location":"#ibm-hyper-protect-services-is-a-service-family-available-in-ibm-cloud-and-ibm-systems-that-achieves-total-data-privacy-assurance-for-the-protection-of-valuable-corporate-assets-and-sensitive-data","text":"From a recent, IBM-sponsored Ponemon Institute Security study , the global average cost of a data breach is $4.35M USD \u2014 and this increases significantly for industries with regulatory concerns. The loss of customer trust had serious financial consequences for the companies studied, and lost business was the largest of four major cost categories that contributed to the total cost of a data breach. The same study also looked at cost mitigation factors that either helped reduce costs preventatively or in the aftermath of a breach. Extensive use of encryption, data loss prevention, threat intelligence sharing and integrating security into the software development process (DevSecOps) were all associated with lower-than-average data breach costs. Among these, encryption had the greatest impact, reducing breach costs by an average of $360,000. Regulatory compliance is another challenge when considering moving sensitive data to the cloud. Requirements can be complex, and penalties can be significant! For example, the Payment Card Industry Data Security Standard (PCI-DSS), fines can range from $5K to $100K USD monthly. Annual recertification averages $15K -$70K. For United States Health Insurance Portability and Accountability Act (HIPAA), fines can be as high as $16M USD. HIPAA Compliance has 250+ validation points and is a 6-month to 3-year process. More recently there have been several regional data privacy laws that have come into effect or are coming soon! For example, the EU\u2019s General Data Protection Regulation (GDPR), the US State of California Consumer Privacy Act, Canada\u2019s Personal Information Protection and Electronic Documents Act (PIPEDA). All these regulations either mandate encryption of data at rest and in transit as required or strongly encourage encryption as a technical measure to protect data. But what about the keys that are used to encrypt? Who has control of the keys? Imagine that you built a house with all the latest safety and security features to protect your loved ones, your valuable possessions and treasured family keepsakes. You have video surveillance, fireproof safes, the latest security system, 24x365 monitoring, a guard dog, and all the latest technology. It is a virtual fortress! Now, you wouldn\u2019t want to give a key to home to just anyone, would you? That could be your one point of vulnerability that you didn\u2019t anticipate or might not be able to control.","title":"IBM Hyper Protect Services is a service family available in IBM Cloud and IBM Systems that achieves total data privacy assurance for the protection of valuable corporate assets and sensitive data."},{"location":"#_2","text":"","title":""},{"location":"#protecting-sensitive-data-is-vital-to-an-enterprises-cloud-data-security-privacy-and-digital-trust","text":"As we enter a new normal period of accelerated digital transformation post-COVID, the vast number of organizations are now relying heavily on public and hybrid cloud services. And companies in highly regulated industries, now more than ever, find themselves needing cloud services that offer a greater level of protection and privacy. The data protection needs of organizations are driven by the concerns about protecting sensitive information, intellectual property, and meeting compliance and regulatory requirements. The dilemma for organizations is how do they independently retain ownership and control of their data while still driving innovation. The more sensitive the data, companies want to have complete authority over their valuable data and associated workloads, including no access to sensitive data for even their cloud providers i.e., they require technical assurance that cloud provider cannot access data rather than relying on operational assurance that cloud provider policies say they will not access data. This is where Confidential Computing capabilities can play a huge part. Per a Confidential Computing Consortium Research Study , the total addressable market (TAM) for Confidential Computing will reach over $50B USD by 2026! Over 75% of demand is driven by regulated industries like banking, finance, insurance, healthcare, life sciences, public sector, and defense in 2021. Awareness of the benefits of CC and willingness to invest in exploration is expected to double across key regulated industries through 2026.","title":"Protecting sensitive data is vital to an enterprise\u2019s cloud data security, privacy and digital trust."},{"location":"#_3","text":"","title":""},{"location":"#ibms-view-of-confidential-computing-is-to-assure-data-privacy-in-the-cloud-with-ibm-cloud-your-data-is-yours","text":"When using IBM\u2019s Confidential Computing capabilities, sensitive data isolated into a protected enclave during processing. The contents of the enclave, data being processed and techniques used to process it are only accessible to authorized code invisible to anything or anyone else including the operating system and cloud provider. IBM as the cloud provider cannot access this data. IBM cannot therefore provide access to third parties even if compelled to do so by external factors. For example, in the case of regulations or rulings like: The \"Schrems II\" Decision , which found the Privacy Shield mechanism for transferring data between the EU and US did not protect EU citizens from bulk surveillance by the US government. The US CLOUD Act , which that allows the US government to subpoena requested data stored on servers regardless of whether the data are stored in the U.S. or on foreign soil IBM cannot turn over customer data. Customers own the encryption keys and the encrypted data.","title":"IBM\u2019s view of confidential computing is to assure data privacy in the cloud. With IBM Cloud, your data is yours."},{"location":"#_4","text":"","title":""},{"location":"#additional-enablement-resources","text":"Numerous other learning paths and resources are available for IBM sellers and business partners. IBM Technology Zone : Use the Unified Key Orchestrator (UKO) to orchestrate keys across AWS and/or Azure IBM HPCS (Encryption) Seismic Sales Kit IBM HPVS (Confidential Compute & Digital Assets) Seismic Sales Kit Use these assets to bolster your skills and delight clients.","title":"Additional enablement resources"},{"location":"#_5","text":"","title":""},{"location":"#next-steps","text":"As part of the hands-on experience of this Level 3 curriculum, you will learn how IBM Hyper Protect Services are helping to protect data with technical assurance to reduce the risk of a data breach, enhances data privacy and sovereignity, and protects what is most valuable to IBM clients with the speed, ease, and efficieny of cloud-native solutions.","title":"Next steps"},{"location":"evaluation/","text":"Evaluation Criteria for IBM Technical Sellers and Business Partners To receive Level 3 accreditation, IBMers and Business Partners must demonstrate mastery of the skills learned throughout the various modules of these hands-on labs and coursework. Level 3 accreditation requirements\u2014 and the way participants will be evaluated before receiving accreditation \u2014differs depending on job role. IBM TECHNICAL SELLERS IBM Sales and Tech Sales must develop and record a Stand & Deliver presentation. This video is intended to simulate your delivery of a \u201clive\u201d demo in front of a client \u2014 on camera. IBMers will have flexibility in defining a hypothetical client, the pain points that customer has, and the goals they aspire to. The recording will then cover the seller\u2019s hands-on demonstration and pitch to the client of the value of the IBM solution using the techniques of this lab. BUSINESS PARTNERS Business Partners must pass an accreditation quiz with a grade of 75% or higher after completing the hands-on portion of the course. The quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question. The quiz questions will ask you about on-screen text or descriptions that come up as you work through the lab guide. IBMer Stand & Deliver Assessment IBMers \u2014 SUBMIT RECORDINGS HERE Submit your Stand & Deliver recording online using IBM YourLearning: < LINK GOES HERE > The evaluation criteria described below and on Seismic only applies to IBMers , who must record a Stand & Deliver presentation to receive accreditation for this Level 3 course. IBMers will be evaluated by First Line Manager (FLM). Instructions on how to submit a Stand & Deliver are included on this page. You must incorporate Requirements 1 through 4 from BOTH the HPCS and HPVS modules as part of your Stand & Deliver recording. Click to expand each of the following tabs to view the evaluation criteria for each module. REQUIREMENTS \u2014 HYPER PROTECT CRYPTO SERVICES ( HPCS ) Articulate the value of IBM Cloud Hyper Protect Crypto Services with Unified Key Orchestrator in a way that relates to current client needs and/or pain point(s). Especially: The need to protect data with encryption keys which are in the control of the client to enhance data security, data privacy and data sovereignty as well as compliance posture (for regulated clients). The differences in security posture of the different available key management options across cloud, i.e. CSP managed encryption, BYOK, HYOK & KYOK. Explain the Concepts of Key Vaults, Key Stores and Keys within the Service UI on cloud.ibm.com Demonstrate the following features of Hyper Protect offerings: How to provision a new service instance of HPCS, the major difference of the standard and the unified key orchestration (UKO) plan (IBM Cloud only and Multi Cloud capabilities) and explain how pricing is set-up Show what a Key Vault is and how it can be used and useful for teams across an organisation with Role Based Access Control (RBAC) Show what a KeyStore is and how you would set it up (without setting it up as Secrets needed for this should not be shared in a demo) Show how to create a key & push a key to an already set AWS KeyStore Show how to encrypt data in an S3 Bucket in AWS with a key created in UKO Show how to manage that key and use the control you would have as a cloud customer over that key by deactivating the key Show the impact of deactivating the key in IBM Cloud HPCS with UKO on access to data in AWS Storage: expected outcome: encrypted object in the S3 storage is not accessible anymore. Explain how that enhanced the control and therefore security posture of the User. Show how to activate the key again & how that makes the encrypted objects in AWS S3 Service available to use again, as it can be decrypted. Explain that this is also a risk mitigation, in case a Key in AWS gets lost or stolen, as it is securely backed up in IBM Cloud. REQUIREMENTS \u2014 HYPER PROTECT VIRTUAL SERVERS ( HPVS ) Articulate the value of IBM Cloud Hyper Protect Virtual Servers in a way that relates to current client needs and/or pain point(s). Especially: The need to protect data in use Explain the concept of Confidential Compute and the benefits, including how Hyper Protect Virtual Servers for VPC spins up a Confidential Compute Environment to run fully protected containerized workloads The value of having Technical Assurance in IBM Cloud and how that helps to minimize attack vectors and enhance total data privacy assurance Demonstrate the following features of Hyper Protect offerings: How to use Terraform to create a contract to deploy the containerized Workload of the sample \u201cPayNow\u201d Application onto Hyper Protect Virtual Server for VPC Explain the different parts of a contract and what a contract is used for Show how to find Hyper Protect Virtual Servers for VPC in IBM Cloud and set the correct variables on the Service Creation Page (IBM Z/ LinuxONE and enable Confidential Compute) Explain (while doing so) the benefits of leveraging Secure Execution based on IBM Z (Security based on Trust in Hardware = Technical Assurance) for Confidential Compute Show that there are different profiles, which can be chosen based on clients needs Insert the contract into the User Data Field (OPTIONAL) : If you choose to deploy a live application environment in your personal IBM Cloud account: Create the instance to deploy the Confidential Container based on the Variables in the contract Show the logs of the instance Once the Application is up and running \u2013 Use the IP address to show the Web-Application which Explain how that data being processed by that application is now protected while in use Leverage the MediaCenter Video to show the full attack scenario by a potential attacker and how Confidential Compute with Hyper Protect prevents that successfully Business Partner Quiz Assessment PARTNERS \u2014 COMPLETE ASSESSMENT HERE Complete your assessment online using IBM Training: < LINK GOES HERE > The accreditation quiz consists of five multiple choice questions, each with four possible responses (and only one correct answer) for each question. Partners must pass with quiz with a grade of 75% or higher to receive accreditation. The quiz questions draw upon material that is covered in both the HPCS and HPVS modules.","title":"Evaluation"},{"location":"evaluation/#evaluation-criteria-for-ibm-technical-sellers-and-business-partners","text":"To receive Level 3 accreditation, IBMers and Business Partners must demonstrate mastery of the skills learned throughout the various modules of these hands-on labs and coursework. Level 3 accreditation requirements\u2014 and the way participants will be evaluated before receiving accreditation \u2014differs depending on job role. IBM TECHNICAL SELLERS IBM Sales and Tech Sales must develop and record a Stand & Deliver presentation. This video is intended to simulate your delivery of a \u201clive\u201d demo in front of a client \u2014 on camera. IBMers will have flexibility in defining a hypothetical client, the pain points that customer has, and the goals they aspire to. The recording will then cover the seller\u2019s hands-on demonstration and pitch to the client of the value of the IBM solution using the techniques of this lab. BUSINESS PARTNERS Business Partners must pass an accreditation quiz with a grade of 75% or higher after completing the hands-on portion of the course. The quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question. The quiz questions will ask you about on-screen text or descriptions that come up as you work through the lab guide.","title":"Evaluation Criteria for IBM Technical Sellers and Business Partners"},{"location":"evaluation/#_1","text":"","title":""},{"location":"evaluation/#ibmer-stand-deliver-assessment","text":"IBMers \u2014 SUBMIT RECORDINGS HERE Submit your Stand & Deliver recording online using IBM YourLearning: < LINK GOES HERE > The evaluation criteria described below and on Seismic only applies to IBMers , who must record a Stand & Deliver presentation to receive accreditation for this Level 3 course. IBMers will be evaluated by First Line Manager (FLM). Instructions on how to submit a Stand & Deliver are included on this page. You must incorporate Requirements 1 through 4 from BOTH the HPCS and HPVS modules as part of your Stand & Deliver recording. Click to expand each of the following tabs to view the evaluation criteria for each module. REQUIREMENTS \u2014 HYPER PROTECT CRYPTO SERVICES ( HPCS ) Articulate the value of IBM Cloud Hyper Protect Crypto Services with Unified Key Orchestrator in a way that relates to current client needs and/or pain point(s). Especially: The need to protect data with encryption keys which are in the control of the client to enhance data security, data privacy and data sovereignty as well as compliance posture (for regulated clients). The differences in security posture of the different available key management options across cloud, i.e. CSP managed encryption, BYOK, HYOK & KYOK. Explain the Concepts of Key Vaults, Key Stores and Keys within the Service UI on cloud.ibm.com Demonstrate the following features of Hyper Protect offerings: How to provision a new service instance of HPCS, the major difference of the standard and the unified key orchestration (UKO) plan (IBM Cloud only and Multi Cloud capabilities) and explain how pricing is set-up Show what a Key Vault is and how it can be used and useful for teams across an organisation with Role Based Access Control (RBAC) Show what a KeyStore is and how you would set it up (without setting it up as Secrets needed for this should not be shared in a demo) Show how to create a key & push a key to an already set AWS KeyStore Show how to encrypt data in an S3 Bucket in AWS with a key created in UKO Show how to manage that key and use the control you would have as a cloud customer over that key by deactivating the key Show the impact of deactivating the key in IBM Cloud HPCS with UKO on access to data in AWS Storage: expected outcome: encrypted object in the S3 storage is not accessible anymore. Explain how that enhanced the control and therefore security posture of the User. Show how to activate the key again & how that makes the encrypted objects in AWS S3 Service available to use again, as it can be decrypted. Explain that this is also a risk mitigation, in case a Key in AWS gets lost or stolen, as it is securely backed up in IBM Cloud. REQUIREMENTS \u2014 HYPER PROTECT VIRTUAL SERVERS ( HPVS ) Articulate the value of IBM Cloud Hyper Protect Virtual Servers in a way that relates to current client needs and/or pain point(s). Especially: The need to protect data in use Explain the concept of Confidential Compute and the benefits, including how Hyper Protect Virtual Servers for VPC spins up a Confidential Compute Environment to run fully protected containerized workloads The value of having Technical Assurance in IBM Cloud and how that helps to minimize attack vectors and enhance total data privacy assurance Demonstrate the following features of Hyper Protect offerings: How to use Terraform to create a contract to deploy the containerized Workload of the sample \u201cPayNow\u201d Application onto Hyper Protect Virtual Server for VPC Explain the different parts of a contract and what a contract is used for Show how to find Hyper Protect Virtual Servers for VPC in IBM Cloud and set the correct variables on the Service Creation Page (IBM Z/ LinuxONE and enable Confidential Compute) Explain (while doing so) the benefits of leveraging Secure Execution based on IBM Z (Security based on Trust in Hardware = Technical Assurance) for Confidential Compute Show that there are different profiles, which can be chosen based on clients needs Insert the contract into the User Data Field (OPTIONAL) : If you choose to deploy a live application environment in your personal IBM Cloud account: Create the instance to deploy the Confidential Container based on the Variables in the contract Show the logs of the instance Once the Application is up and running \u2013 Use the IP address to show the Web-Application which Explain how that data being processed by that application is now protected while in use Leverage the MediaCenter Video to show the full attack scenario by a potential attacker and how Confidential Compute with Hyper Protect prevents that successfully","title":"IBMer Stand &amp; Deliver Assessment"},{"location":"evaluation/#_2","text":"","title":""},{"location":"evaluation/#business-partner-quiz-assessment","text":"PARTNERS \u2014 COMPLETE ASSESSMENT HERE Complete your assessment online using IBM Training: < LINK GOES HERE > The accreditation quiz consists of five multiple choice questions, each with four possible responses (and only one correct answer) for each question. Partners must pass with quiz with a grade of 75% or higher to receive accreditation. The quiz questions draw upon material that is covered in both the HPCS and HPVS modules.","title":"Business Partner Quiz Assessment"},{"location":"HPCS/01-Introduction-to-HPCS-and-UKO/","text":"IBM Cloud Hyper Protect Crypto Services and Unified Key Orchestrator WATCH THIS DEMONSTRATION Louisa Muschal (Product Manager, IBM Hyper Protect Services - GTM) explains the value of IBM Cloud Hyper Protect Crypto Services and sets the stage for the hands-on work of this module. Additional ways to watch: Seismic replay available for download. Welcome to the IBM Cloud Hyper Protect Crypto Services hands-on demonstration, where sellers and business partners will have the opportunity to test the functionality of the Unified Key Orchestrator across IBM Cloud and AWS environments. IBM Cloud Hyper Protect Crypto Services ( HPCS ) provides data encryption that\u2019s protected by a dedicated cloud hardware security module and enables multicloud key management. UKO, a component of HPCS, is what enables key orchestration across these multicloud environments. HPCS is built on FIPS 140-2 Level 4 certified hardware, the highest level in the industry. Unified Key Orchestrator ( UKO ) is a multi-cloud key management solution offered as a managed service on IBM Cloud. Built on \u2018Keep Your Own Key\u2019 (KYOK), UKO helps enterprises manage their data encryption keys over multiple key stores and across multiple clouds environments. These key environments include managed on-premises stores and keys on IBM Cloud, AWS, and Microsoft Azure. UKO manages and orchestrates these security policies from a single point of control. BRING YOUR OWN KEY vs. KEEP YOUR OWN KEY How does the \"Keep Your Own Key\" (KYOK) approach of UKO differ from \"Bring Your Own Key\" (BYOK)? BYOK is a way for clients to use their own keys to encrypt data. Key management services that provide BYOK are typically multi-tenant services. With these services, users can import encryption keys from on-premises hardware security modules (HSM) and then manage the keys. KYOK includes all of the capabilities of BYOK, but also provides technical assurances that IBM cannot access a client's keys. With KYOK, clients have exclusive control of the entire key hierarchy, including that of the master key. The following table provides further details on the differences between BYOK and KYOK: Key benefits to HPCS clients Lifecycle management for keys : A GUI and a REST API track keys as they progress. Deleted data is no longer retrievable, regardless of the application that stored it. Learn more. Encryption for IBM Cloud services : IBM Cloud services can integrate with this product. Clients receive a common-key-provider API for a consistent approach in IBM Cloud adoption. Learn more. Multicloud key management : Extend protection across cloud deployments. Manage all keys in one place, with added protection and simplicity. Learn more. Security certification : The service is built on FIPS 140-2 Level-4-certified hardware\u2014the highest offered by any cloud provider in the industry. Learn more. HSM control : Single-tenant, dedicated HSMs are controlled by you. IBM Cloud administrators have no access. Learn more. Key ceremony : IBM is the first to provide cloud command-line interface (smart cards) for the HSM key ceremony. Learn more. Next steps In the following section, you will need to review the pre-requisites and follow the provisioning instructions for setting up your IBM Technology Zone environment.","title":"Introduction to HPCS and UKO"},{"location":"HPCS/01-Introduction-to-HPCS-and-UKO/#ibm-cloud-hyper-protect-crypto-services-and-unified-key-orchestrator","text":"WATCH THIS DEMONSTRATION Louisa Muschal (Product Manager, IBM Hyper Protect Services - GTM) explains the value of IBM Cloud Hyper Protect Crypto Services and sets the stage for the hands-on work of this module. Additional ways to watch: Seismic replay available for download. Welcome to the IBM Cloud Hyper Protect Crypto Services hands-on demonstration, where sellers and business partners will have the opportunity to test the functionality of the Unified Key Orchestrator across IBM Cloud and AWS environments. IBM Cloud Hyper Protect Crypto Services ( HPCS ) provides data encryption that\u2019s protected by a dedicated cloud hardware security module and enables multicloud key management. UKO, a component of HPCS, is what enables key orchestration across these multicloud environments. HPCS is built on FIPS 140-2 Level 4 certified hardware, the highest level in the industry. Unified Key Orchestrator ( UKO ) is a multi-cloud key management solution offered as a managed service on IBM Cloud. Built on \u2018Keep Your Own Key\u2019 (KYOK), UKO helps enterprises manage their data encryption keys over multiple key stores and across multiple clouds environments. These key environments include managed on-premises stores and keys on IBM Cloud, AWS, and Microsoft Azure. UKO manages and orchestrates these security policies from a single point of control. BRING YOUR OWN KEY vs. KEEP YOUR OWN KEY How does the \"Keep Your Own Key\" (KYOK) approach of UKO differ from \"Bring Your Own Key\" (BYOK)? BYOK is a way for clients to use their own keys to encrypt data. Key management services that provide BYOK are typically multi-tenant services. With these services, users can import encryption keys from on-premises hardware security modules (HSM) and then manage the keys. KYOK includes all of the capabilities of BYOK, but also provides technical assurances that IBM cannot access a client's keys. With KYOK, clients have exclusive control of the entire key hierarchy, including that of the master key. The following table provides further details on the differences between BYOK and KYOK:","title":"IBM Cloud Hyper Protect Crypto Services and Unified Key Orchestrator"},{"location":"HPCS/01-Introduction-to-HPCS-and-UKO/#_1","text":"","title":""},{"location":"HPCS/01-Introduction-to-HPCS-and-UKO/#key-benefits-to-hpcs-clients","text":"Lifecycle management for keys : A GUI and a REST API track keys as they progress. Deleted data is no longer retrievable, regardless of the application that stored it. Learn more. Encryption for IBM Cloud services : IBM Cloud services can integrate with this product. Clients receive a common-key-provider API for a consistent approach in IBM Cloud adoption. Learn more. Multicloud key management : Extend protection across cloud deployments. Manage all keys in one place, with added protection and simplicity. Learn more. Security certification : The service is built on FIPS 140-2 Level-4-certified hardware\u2014the highest offered by any cloud provider in the industry. Learn more. HSM control : Single-tenant, dedicated HSMs are controlled by you. IBM Cloud administrators have no access. Learn more. Key ceremony : IBM is the first to provide cloud command-line interface (smart cards) for the HSM key ceremony. Learn more.","title":"Key benefits to HPCS clients"},{"location":"HPCS/01-Introduction-to-HPCS-and-UKO/#_2","text":"","title":""},{"location":"HPCS/01-Introduction-to-HPCS-and-UKO/#next-steps","text":"In the following section, you will need to review the pre-requisites and follow the provisioning instructions for setting up your IBM Technology Zone environment.","title":"Next steps"},{"location":"HPCS/02-Provision-and-access/","text":"Provisioning an IBM Technology Zone environment IBM TECHNOLOGY ZONE You will require access to the IBM Technology Zone in order to reserve your environment and complete the hands-on training. If you do not yet have access or an account with the ITZ, you may register for one by visiting the following page: https://techzone.ibm.com In this section, you will provision and request access to an IBM Technology Zone (ITZ) environment where Hyper Protect Crypto Services (HPCS) and Unified Key Orchestrator (UKO) have been preconfigured for demonstration purposes. The keystores associated with this ITZ environment have already been linked to specific accounts that IBM administrates in Amazon Web Services (AWS) and Microsoft Azure public clouds. The hands-on environment can be provisioned free-of-charge using the reservation portal: https://techzone.ibm.com/collection/use-the-unified-key-orchestrator-uko-to-orchestrate-keys-across-aws-andor-azure/environments MULTIPLE ENVIRONMENT TEMPLATES ITZ will display two configurations to choose from. You will need to provision both the IBM Cloud HPCS and AWS Account Access tiles. The following instructions will guide you through how to do this. Select the Access to IBM Cloud HPCS tile by clicking the blue Reserve icon. You may select the option to Reserve now (recommended) or Schedule for later . In order to complete your ITZ reservation of the HPCS environment, you must supply the following information: Name : Give your reservation a unique name. Purpose : Set to Practice / Self-Education and affirm that the environment will not be used with customer data. If you are replicating this hands-on demonstration with a client, you must select Customer Demo and supply a sales opportunity number. Purpose Description : Provide a brief summary of how the environment will be used. Preferred Geography : US-East (VPC) End Date & Time : Select a time and date for when the reservation will expire. The recommended amount is 2 days, although it is possible to finish the hands-on demonstration within a few hours. When satisfied, verify that you agree to the Terms and Conditions for the environment and finalize your reservation request by clicking Submit . Reservations take approximately 15-20 minutes to complete from the time that you click submit. If you navigate to the My Reservations tab of the ITZ, you can monitor the progress of your reservation. WAIT UNTIL READY Wait for the ITZ reservation to be marked as \" Ready \" before attempting to start the lab \u2014 accessing it too soon will lead to issues (or an outright failure) when connecting to the HPCS instance. You will also receive an email to your inbox once the environment has successfully deployed. The \"Your environment is ready\" email contains links back to the My Reservations tab, which now is populated with all of the details needed to access your IBM Cloud HPCS environment. Repeat the same reservation Steps 2 through 6 for the AWS Account Access instance. You will need to wait for both instances (IBM HPCS and AWS) to finish provisioning through the My Reservations tab of the ITZ before continuing with the lab. Accessing the HPCS and AWS environments For the IBM Cloud HPCS environment, you will receive an email (see Step 6) with an invitation to connect your personal IBM Cloud account to an ITZ V2 account, as shown in the following screenshot. You must ACCEPT the invitation by clicking the Join Now button in the email. A web browser will open and direct you to log in to your IBM Cloud account. Proceed and then accept the ITZ V2 invitation when prompted to do so. Once authenticated and logged in, look for a drop-down in the top-right corner of the IBM Cloud interface and click it to toggle between different Organizations / Resource Groups. You should see ITZ V2 listed, potentially alongside multiple others. Click the ITZ V2 group and wait for the browser to refresh. From the left-hand interface, click the Resource List icon (three stacked and bulleted lines) and drill down in the Security row. You should see an HPCS instance similar to the one shown in the following screenshot. For retrieving the AWS Account Access that was requested in Step 7, return to your email inbox and look for an email stating that the AWS environment is ready (similar to the screenshot provided below). Record the AWS Access Group , AWS SSO User Portal URL , and Desktop details provided in the note. Alternatively, you can always retrieve this information from the My Reservations tab of the ITZ. Click the Desktop link in the email or navigate to https://techzone.awsapps.com/start to get started. When prompted, authenticate using your personal IBMid to continue to the AWS dashboard, as shown below. Click on the AWS Account (1) tile and drill down into the UKO User Management Console , which will redirect the web browser to a page resembling the following screenshot. Under the Console Home panel, multiple links are provided: Key Management Service , IAM , AWS Budgets , AWS Organizations , and so on. Select the Key Management Service link. From the drop-down in the top-right corner of the AWS dashboard, ensure that the US East (N. Virginia) region is selected. It should be set as such by default, but if it has been configured to something else, set it back to US East. CAUTION Do not modify or delete this key. If the key does not appear, verify that the US East (N. Virginia) region was selected in Step 17. If the key is still missing, reach out to the author of this documentation. Drill down into Key Management Service > Customer-managed keys : confirm that under the Aliases column is a key labelled TechZone-UKO-Key . Next steps Now that you have successfully provisioned and gained access to both IBM Cloud HPCS and AWS Key Management Service, we will next go ahead with generating your own key in AWS Keystore.","title":"Provision and access an IBM Technology Zone environment"},{"location":"HPCS/02-Provision-and-access/#provisioning-an-ibm-technology-zone-environment","text":"IBM TECHNOLOGY ZONE You will require access to the IBM Technology Zone in order to reserve your environment and complete the hands-on training. If you do not yet have access or an account with the ITZ, you may register for one by visiting the following page: https://techzone.ibm.com In this section, you will provision and request access to an IBM Technology Zone (ITZ) environment where Hyper Protect Crypto Services (HPCS) and Unified Key Orchestrator (UKO) have been preconfigured for demonstration purposes. The keystores associated with this ITZ environment have already been linked to specific accounts that IBM administrates in Amazon Web Services (AWS) and Microsoft Azure public clouds. The hands-on environment can be provisioned free-of-charge using the reservation portal: https://techzone.ibm.com/collection/use-the-unified-key-orchestrator-uko-to-orchestrate-keys-across-aws-andor-azure/environments MULTIPLE ENVIRONMENT TEMPLATES ITZ will display two configurations to choose from. You will need to provision both the IBM Cloud HPCS and AWS Account Access tiles. The following instructions will guide you through how to do this. Select the Access to IBM Cloud HPCS tile by clicking the blue Reserve icon. You may select the option to Reserve now (recommended) or Schedule for later . In order to complete your ITZ reservation of the HPCS environment, you must supply the following information: Name : Give your reservation a unique name. Purpose : Set to Practice / Self-Education and affirm that the environment will not be used with customer data. If you are replicating this hands-on demonstration with a client, you must select Customer Demo and supply a sales opportunity number. Purpose Description : Provide a brief summary of how the environment will be used. Preferred Geography : US-East (VPC) End Date & Time : Select a time and date for when the reservation will expire. The recommended amount is 2 days, although it is possible to finish the hands-on demonstration within a few hours. When satisfied, verify that you agree to the Terms and Conditions for the environment and finalize your reservation request by clicking Submit . Reservations take approximately 15-20 minutes to complete from the time that you click submit. If you navigate to the My Reservations tab of the ITZ, you can monitor the progress of your reservation. WAIT UNTIL READY Wait for the ITZ reservation to be marked as \" Ready \" before attempting to start the lab \u2014 accessing it too soon will lead to issues (or an outright failure) when connecting to the HPCS instance. You will also receive an email to your inbox once the environment has successfully deployed. The \"Your environment is ready\" email contains links back to the My Reservations tab, which now is populated with all of the details needed to access your IBM Cloud HPCS environment. Repeat the same reservation Steps 2 through 6 for the AWS Account Access instance. You will need to wait for both instances (IBM HPCS and AWS) to finish provisioning through the My Reservations tab of the ITZ before continuing with the lab.","title":"Provisioning an IBM Technology Zone environment"},{"location":"HPCS/02-Provision-and-access/#_1","text":"","title":""},{"location":"HPCS/02-Provision-and-access/#accessing-the-hpcs-and-aws-environments","text":"For the IBM Cloud HPCS environment, you will receive an email (see Step 6) with an invitation to connect your personal IBM Cloud account to an ITZ V2 account, as shown in the following screenshot. You must ACCEPT the invitation by clicking the Join Now button in the email. A web browser will open and direct you to log in to your IBM Cloud account. Proceed and then accept the ITZ V2 invitation when prompted to do so. Once authenticated and logged in, look for a drop-down in the top-right corner of the IBM Cloud interface and click it to toggle between different Organizations / Resource Groups. You should see ITZ V2 listed, potentially alongside multiple others. Click the ITZ V2 group and wait for the browser to refresh. From the left-hand interface, click the Resource List icon (three stacked and bulleted lines) and drill down in the Security row. You should see an HPCS instance similar to the one shown in the following screenshot. For retrieving the AWS Account Access that was requested in Step 7, return to your email inbox and look for an email stating that the AWS environment is ready (similar to the screenshot provided below). Record the AWS Access Group , AWS SSO User Portal URL , and Desktop details provided in the note. Alternatively, you can always retrieve this information from the My Reservations tab of the ITZ. Click the Desktop link in the email or navigate to https://techzone.awsapps.com/start to get started. When prompted, authenticate using your personal IBMid to continue to the AWS dashboard, as shown below. Click on the AWS Account (1) tile and drill down into the UKO User Management Console , which will redirect the web browser to a page resembling the following screenshot. Under the Console Home panel, multiple links are provided: Key Management Service , IAM , AWS Budgets , AWS Organizations , and so on. Select the Key Management Service link. From the drop-down in the top-right corner of the AWS dashboard, ensure that the US East (N. Virginia) region is selected. It should be set as such by default, but if it has been configured to something else, set it back to US East. CAUTION Do not modify or delete this key. If the key does not appear, verify that the US East (N. Virginia) region was selected in Step 17. If the key is still missing, reach out to the author of this documentation. Drill down into Key Management Service > Customer-managed keys : confirm that under the Aliases column is a key labelled TechZone-UKO-Key .","title":"Accessing the HPCS and AWS environments"},{"location":"HPCS/02-Provision-and-access/#_2","text":"","title":""},{"location":"HPCS/02-Provision-and-access/#next-steps","text":"Now that you have successfully provisioned and gained access to both IBM Cloud HPCS and AWS Key Management Service, we will next go ahead with generating your own key in AWS Keystore.","title":"Next steps"},{"location":"HPCS/03-Create-a-key/","text":"Generating a unique key with the AWS Keystore Previously, we provisioned and inspected encryption keys in AWS that were generated ahead of time by IBM Technology Zone. In the following section, you will generate an encryption key that can be later be used for managing resources accessed within the AWS environment. Return to the IBM Cloud dashboard and drill down into Resource List > Security , then click the name of the Hyper Protect Crypto Services-Techzone instance. The browser will redirect to a management panel for the HPCS instance. From the left-hand side of the interface, drill down into Vaults > Managed Keys and take note of the inventory of keys available. Two keys should be listed: TechZone-UKO-Key and UKO-Azure-Test-Key . Along the top-right corner of the Managed Keys table, locate and click the blue Create Key + button, as shown. SHARED ENVIRONMENT When selecting a Name for your key, be aware that other sellers and business partners enrolled in this Level 3 course will be able to see keys created in the shared HPCS environment. Do not use the names of clients or other confidential information as part of your key definition. You will be asked to supply the following information as part of the key definition: Specify the Target Vault : Tech Zone Vault Specify the Keystore Type : AWS Key Management Service Specify the Key Properties , which include: a unique Name ; State: Active ; and Expiration Date set three days into the future. Specify the Target Keystore : AWS Tech Zone Under the Summary tab, review the selections and when satisfied click the Create Key button. Validate encryption key generation on AWS Return to the AWS dashboard and open the Key Management Service (KMS) panel as before. From the left-side of the interface, drill down into the Customer-managed keys section. Examine the contents and look for the uniquely generated key that you created using the Unified Key Orchestrator (UKO) in Step 3. MISSING KEY If the key is not displayed, verify once again that your AWS dashboard is set to the US East (N. Virginia) region using the drop-down in the top-right corner of the interface. Test the key by encrypting AWS S3 bucket contents Locate the search bar at the top of the AWS dashboard. Search for s3 and click on the AWS S3 service result. Wait for the AWS S3 dashboard to load. From the left-hand side of the interface, drill down into Buckets and then click the orange Create Bucket button as shown. Provide the following details as you create a new S3 bucket: Name : Set to a unique identifier of your choosing. Region : Set to US East (N. Virginia) to match the region where your encryption key is located. Leave the ACLs and Bucket Versioning fields as Disabled . Encryption set to ENABLED with the AWS Key Management Service Key (SSE-KMS) option selected. Select the Choose from your AWS KMS keys option and specify the unique key generated in Step 5 from the dropdown menu. Note: The key will need to be identified by the KeyID field (found within the KMS Console in AWS); it will not be listed under the Name identifier you assigned upon key generation. Review the selections made and when satisfied click the Create Bucket option to continue. After creating the S3 bucket, the web browser will redirect back to the AWS S3 dashboard. Scroll down the page until you reach Buckets table and locate the newly-created bucket in the list. Click the name of the bucket to drill down further. With the bucket selected, click the orange Upload button and select a small file from your machine (one of the L3 lab documents, for example) to upload. No sensitive or confidential information, please. Wait for the asset to upload and be listed as an Object within the bucket. Click on the file name to see the object properties. To ensure that the file was properly uploaded and available for download, click on the Download button in the top-right corner of the interface. Open the file on your desktop to verify its integrity. Next steps With the AWS S3 bucket and encryption key now prepared, we will demonstrate how to digitally shred objects within AWS S3 using the HPCS Unified Key Orchestrator (UKO).","title":"Generating a unique key with the AWS Keystore"},{"location":"HPCS/03-Create-a-key/#generating-a-unique-key-with-the-aws-keystore","text":"Previously, we provisioned and inspected encryption keys in AWS that were generated ahead of time by IBM Technology Zone. In the following section, you will generate an encryption key that can be later be used for managing resources accessed within the AWS environment. Return to the IBM Cloud dashboard and drill down into Resource List > Security , then click the name of the Hyper Protect Crypto Services-Techzone instance. The browser will redirect to a management panel for the HPCS instance. From the left-hand side of the interface, drill down into Vaults > Managed Keys and take note of the inventory of keys available. Two keys should be listed: TechZone-UKO-Key and UKO-Azure-Test-Key . Along the top-right corner of the Managed Keys table, locate and click the blue Create Key + button, as shown. SHARED ENVIRONMENT When selecting a Name for your key, be aware that other sellers and business partners enrolled in this Level 3 course will be able to see keys created in the shared HPCS environment. Do not use the names of clients or other confidential information as part of your key definition. You will be asked to supply the following information as part of the key definition: Specify the Target Vault : Tech Zone Vault Specify the Keystore Type : AWS Key Management Service Specify the Key Properties , which include: a unique Name ; State: Active ; and Expiration Date set three days into the future. Specify the Target Keystore : AWS Tech Zone Under the Summary tab, review the selections and when satisfied click the Create Key button.","title":"Generating a unique key with the AWS Keystore"},{"location":"HPCS/03-Create-a-key/#_1","text":"","title":""},{"location":"HPCS/03-Create-a-key/#validate-encryption-key-generation-on-aws","text":"Return to the AWS dashboard and open the Key Management Service (KMS) panel as before. From the left-side of the interface, drill down into the Customer-managed keys section. Examine the contents and look for the uniquely generated key that you created using the Unified Key Orchestrator (UKO) in Step 3. MISSING KEY If the key is not displayed, verify once again that your AWS dashboard is set to the US East (N. Virginia) region using the drop-down in the top-right corner of the interface.","title":"Validate encryption key generation on AWS"},{"location":"HPCS/03-Create-a-key/#_2","text":"","title":""},{"location":"HPCS/03-Create-a-key/#test-the-key-by-encrypting-aws-s3-bucket-contents","text":"Locate the search bar at the top of the AWS dashboard. Search for s3 and click on the AWS S3 service result. Wait for the AWS S3 dashboard to load. From the left-hand side of the interface, drill down into Buckets and then click the orange Create Bucket button as shown. Provide the following details as you create a new S3 bucket: Name : Set to a unique identifier of your choosing. Region : Set to US East (N. Virginia) to match the region where your encryption key is located. Leave the ACLs and Bucket Versioning fields as Disabled . Encryption set to ENABLED with the AWS Key Management Service Key (SSE-KMS) option selected. Select the Choose from your AWS KMS keys option and specify the unique key generated in Step 5 from the dropdown menu. Note: The key will need to be identified by the KeyID field (found within the KMS Console in AWS); it will not be listed under the Name identifier you assigned upon key generation. Review the selections made and when satisfied click the Create Bucket option to continue. After creating the S3 bucket, the web browser will redirect back to the AWS S3 dashboard. Scroll down the page until you reach Buckets table and locate the newly-created bucket in the list. Click the name of the bucket to drill down further. With the bucket selected, click the orange Upload button and select a small file from your machine (one of the L3 lab documents, for example) to upload. No sensitive or confidential information, please. Wait for the asset to upload and be listed as an Object within the bucket. Click on the file name to see the object properties. To ensure that the file was properly uploaded and available for download, click on the Download button in the top-right corner of the interface. Open the file on your desktop to verify its integrity.","title":"Test the key by encrypting AWS S3 bucket contents"},{"location":"HPCS/03-Create-a-key/#_3","text":"","title":""},{"location":"HPCS/03-Create-a-key/#next-steps","text":"With the AWS S3 bucket and encryption key now prepared, we will demonstrate how to digitally shred objects within AWS S3 using the HPCS Unified Key Orchestrator (UKO).","title":"Next steps"},{"location":"HPCS/04-Digitally-shred/","text":"Digitally shred AWS S3 bucket objects with Unified Key Orchestrator Owing to the steps taken in the previous section, all objects housed within in the AWS S3 bucket are now encrypted using a uniquely-generated encryption key. Recall that this key\u2014 which you defined \u2014was generated using the Unified Key Orchestrator (UKO) utility of IBM Cloud HPCS. By deactivating this key via UKO on IBM Cloud, any data encrypted with the key (including the bucket storage on AWS S3) will become inaccesible. In effect, disabling the encryption key will digitally shred all data encrypted with said key. This is incredibly useful for rendering inert and inaccessible vast amounts of encrypted data with a single action; far more expedient than seeking out and shredding (through some other process) assets on an individual basis. Return to the IBM Cloud dashboard and drill down into the HPCS UKO instance as done previously. From the HPCS UKO dashboard, navigate using the left-hand interface into Vaults > Managed Keys . Locate the unique encryption key that you generated in the previous section. At the far-right side of the key's row (adjacent the Length column) are three vertically stacked dots. Click the icon and then select Deactivate from the drop-down options. You will presented with two warning statements \u2014 click the checkbox next to each warning, and finally click the Deactivate Key button to finalize the request. DEACTIVATED KEYS Once the key has been deactivated, you will no longer see it listed within the Managed Keys section of the HPCS UKO dashboard. By default, the dashboard will hide all deactivated keys. However, the deactivated key can be viewed by adjusting the filter parameters. Click the X next to the tags along the top of the table to adjust the filters. Return to the AWS dashboard and drill down into the Key Management Service instance as done previously (search for KMS from the top search bar if you have difficulty locating it). From the left-hand side of the interface, drill down into the Customer-managed keys section. Note that the key generated by UKO previously now has a Status of Pending import . This confirms that the encryption key has been deactivated by UKO. KEY ID Recall from the previous section that the AWS Key Management Service lists customer-managed keys by Key ID hash strings, not the name of the key itself (which you specified when first generating the key). From the AWS dashboard, navigate back to the S3 buckets that were set up in the previous section. You will find that the object you uploaded earlier into the bucket is no longer accessible as a result of the key deactivation. Instead, your web browser will return an error similar to the one captured below. Next steps Before continuing with the lab, there are some loose ends to tie and tidying up to perform.","title":"Digitally shred AWS S3 objects"},{"location":"HPCS/04-Digitally-shred/#digitally-shred-aws-s3-bucket-objects-with-unified-key-orchestrator","text":"Owing to the steps taken in the previous section, all objects housed within in the AWS S3 bucket are now encrypted using a uniquely-generated encryption key. Recall that this key\u2014 which you defined \u2014was generated using the Unified Key Orchestrator (UKO) utility of IBM Cloud HPCS. By deactivating this key via UKO on IBM Cloud, any data encrypted with the key (including the bucket storage on AWS S3) will become inaccesible. In effect, disabling the encryption key will digitally shred all data encrypted with said key. This is incredibly useful for rendering inert and inaccessible vast amounts of encrypted data with a single action; far more expedient than seeking out and shredding (through some other process) assets on an individual basis. Return to the IBM Cloud dashboard and drill down into the HPCS UKO instance as done previously. From the HPCS UKO dashboard, navigate using the left-hand interface into Vaults > Managed Keys . Locate the unique encryption key that you generated in the previous section. At the far-right side of the key's row (adjacent the Length column) are three vertically stacked dots. Click the icon and then select Deactivate from the drop-down options. You will presented with two warning statements \u2014 click the checkbox next to each warning, and finally click the Deactivate Key button to finalize the request. DEACTIVATED KEYS Once the key has been deactivated, you will no longer see it listed within the Managed Keys section of the HPCS UKO dashboard. By default, the dashboard will hide all deactivated keys. However, the deactivated key can be viewed by adjusting the filter parameters. Click the X next to the tags along the top of the table to adjust the filters. Return to the AWS dashboard and drill down into the Key Management Service instance as done previously (search for KMS from the top search bar if you have difficulty locating it). From the left-hand side of the interface, drill down into the Customer-managed keys section. Note that the key generated by UKO previously now has a Status of Pending import . This confirms that the encryption key has been deactivated by UKO. KEY ID Recall from the previous section that the AWS Key Management Service lists customer-managed keys by Key ID hash strings, not the name of the key itself (which you specified when first generating the key). From the AWS dashboard, navigate back to the S3 buckets that were set up in the previous section. You will find that the object you uploaded earlier into the bucket is no longer accessible as a result of the key deactivation. Instead, your web browser will return an error similar to the one captured below.","title":"Digitally shred AWS S3 bucket objects with Unified Key Orchestrator"},{"location":"HPCS/04-Digitally-shred/#_1","text":"","title":""},{"location":"HPCS/04-Digitally-shred/#next-steps","text":"Before continuing with the lab, there are some loose ends to tie and tidying up to perform.","title":"Next steps"},{"location":"HPCS/05-Clean-up/","text":"Clean up and conclusion TIDYING UP These environments DO NOT automatically reset. Please ensure you have removed all your keys and adjustments before continuing. Congratulations, you've reached the conclusion of the Hyper Protect Crypto Services (HPCS) Unified Key Orchestration (UKO) demonstration. However, as this environment is multi-tenant and for use by multiple IBMers and business partners, we kindly ask that you take the time to clean up changes you've introduced into the environment before moving on with the other lab modules. IBMers : Before wiping your environment, we recommend taking the time to rehearse and record your Stand and Deliver presentation. As a reminder, in the IBM Cloud HPCS environment you should: Deactivate the encryption keys you have created using UKO. Destroy these keys once they have been deactivated. This will permanently remove them from the environment. DO NOT DELETE KEYS IN THE AWS ENVIRONMENT Only delete keys on the IBM Cloud HPCS environment. These changes will automatically be propagated to the AWS S3 and Key Management Service. Remove these keys from the HPCS UKO vault. Furthermore, if you created any S3 buckets in the AWS environment you should: Delete any S3 buckets you created from the S3 service. A video walkthrough for how to perform these steps is also included within the \"See It\" replays included in the lab.","title":"Clean up and conclusion"},{"location":"HPCS/05-Clean-up/#clean-up-and-conclusion","text":"TIDYING UP These environments DO NOT automatically reset. Please ensure you have removed all your keys and adjustments before continuing. Congratulations, you've reached the conclusion of the Hyper Protect Crypto Services (HPCS) Unified Key Orchestration (UKO) demonstration. However, as this environment is multi-tenant and for use by multiple IBMers and business partners, we kindly ask that you take the time to clean up changes you've introduced into the environment before moving on with the other lab modules.","title":"Clean up and conclusion"},{"location":"HPCS/05-Clean-up/#_1","text":"","title":""},{"location":"HPCS/05-Clean-up/#ibmers-before-wiping-your-environment-we-recommend-taking-the-time-to-rehearse-and-record-your-stand-and-deliver-presentation","text":"As a reminder, in the IBM Cloud HPCS environment you should: Deactivate the encryption keys you have created using UKO. Destroy these keys once they have been deactivated. This will permanently remove them from the environment. DO NOT DELETE KEYS IN THE AWS ENVIRONMENT Only delete keys on the IBM Cloud HPCS environment. These changes will automatically be propagated to the AWS S3 and Key Management Service. Remove these keys from the HPCS UKO vault. Furthermore, if you created any S3 buckets in the AWS environment you should: Delete any S3 buckets you created from the S3 service. A video walkthrough for how to perform these steps is also included within the \"See It\" replays included in the lab.","title":"IBMers: Before wiping your environment, we recommend taking the time to rehearse and record your Stand and Deliver presentation."},{"location":"HPVS/01-Introduction-to-HPVS/","text":"WATCH THIS DEMONSTRATION Louisa Muschal (Product Manager, IBM Hyper Protect Services - GTM) explains the value of IBM Cloud Hyper Protect Virtual Servers for VPC and sets the stage for the hands-on work of this module. Additional ways to watch: Seismic replay available for download. IBM Cloud Hyper Protect Virtual Servers for Virtual Private Cloud IBM Hyper Protect Virtual Server for Virtual Private Cloud (VPC) \u2014 which for the sake of brevity will from this point onward be referred to as HPVS \u2014 is designed to protect cloud-native applications with open container initiative (OCI) deployments that utilize confidential computing. Unique to the market, IBM offers a solution with Secure Execution for Linux. This product in the Hyper Protect family is the next generation of Hyper Protect Virtual Servers and represents a major advancement for the Kubernetes-based offering. The protection boundary has moved from the logical partition level (which includes the operating system and application), to what is now the complete isolation of applications from the operating system. LEARN MORE ABOUT SECURING FINANCIAL TRANSACTIONS WITH HPVS Follow the link (or click the image below) to learn more about Confidential Computing for a financial transaction using HPVS. <a href=\"https://mediacenter.ibm.com/media/Confidential+Computing+for+a+financial+transaction+using+Hyper+Protect+Virtual+Server+for+VPC/1_vv3j2oo6\" target=\"_blank\">![](_attachments/module1_figure1.png){: loading=lazy width=\"400\"}</a> (IBM Media Center asset - 6 minutes runtime) As you progress through this section of the hands-on lab, you will be guided through the steps involved with configuring an HPVS instance on IBM Cloud. Afterwards, you will be provided the instructions needed to reproduce a simulated deployment of a fictitious PayNow application. This process will require the use of Git, Terraform, Hyper Protect \"Contracts\", and navigation of the IBM Cloud interface. Resources Additional HPVS resources that may be beneficial to seller and business partners are available: Sales Kit (Seismic) for HPVS Whitepaper (PDF): \"The Second Generation of IBM Hyper Protect Platform\" Next steps In the following section, you will need to review the pre-requisites and follow the provisioning instructions for setting up your IBM Cloud and local environments. Afterwards, IBM sellers and business partners will learn: How to configure and provision an HPVS instance on IBM Cloud How Contracts are needed to create an HPVS instance with the IBM Hyper Protect Container Runtime (HPCR) image How to deploy a sample application on HPVS COSTS Due to costs that potentially may be incurred from deploying a live HPVS instance on IBM Cloud\u2014 and because sellers and partners must use their own personal IBM Cloud accounts for previewing the IBM Cloud catalog \u2014it is recommended that those taking this course DO NOT deploy any HPVS instances for this Level 3 training, unless: You have a valid client opportunity number, in which case you may use that code to apply for a Hyper Protect Services \"Proof of Concept\" engagement \u2014 which will fund the demo environment for your client opportunity. Follow the procedures outlined HERE for how to apply. You have access to an IBM internal paid account for IBM Cloud, in which case billing will be charged to your respective IBM department, instead of your personal account. Follow the procedures outlined HERE for how to apply. You are willing to accept the charges to your personal IBM account and the credit card associated with that account. The IBM enablement team cannot reimburse such costs and any costs taken on by the IBM account are the responsibility of the user. In lieu of a live production environment, sellers will be furnished with the instruction sets necessary to reproduce these demonstrations as part of a funded client demonstration. Sales opportunity numbers can be applied towards Proof of Experience (PoX) engagements. Documentation for how to do so is included as a part of the coursework resources. IBM sellers and technical sellers , who are required to produce a Stand & Deliver recording of the hands-on demonstration as part of their accreditation process, you will NOT be required to show (on screen) anything beyond the initial configuration steps for Hyper Protect Virtual Servers for VPC on IBM Cloud. Do not deploy the instance, unless you are prepared to finance it on your personal IBM Cloud account. Furthermore, you are not required to record any of the steps involving the hypothetical PayNow application, as doing so would require deployment of a live instance. IBM business partners , who receive accreditation via a passing grade on a multiple-choice test, will only need to answer questions based on the initial configuration steps of Hyper Protect Virtual Servers for VPC on IBM Cloud. Quiz questions will not cover the screen readouts or other material involving either the PayNow application or a fully deployed instance. As mentioned previously, do not deploy the IBM Cloud instance into a live state unless you are prepared to self-finance any potential billing on your personal IBM Cloud account.","title":"Introduction to HPVS"},{"location":"HPVS/01-Introduction-to-HPVS/#_1","text":"","title":""},{"location":"HPVS/01-Introduction-to-HPVS/#ibm-cloud-hyper-protect-virtual-servers-for-virtual-private-cloud","text":"IBM Hyper Protect Virtual Server for Virtual Private Cloud (VPC) \u2014 which for the sake of brevity will from this point onward be referred to as HPVS \u2014 is designed to protect cloud-native applications with open container initiative (OCI) deployments that utilize confidential computing. Unique to the market, IBM offers a solution with Secure Execution for Linux. This product in the Hyper Protect family is the next generation of Hyper Protect Virtual Servers and represents a major advancement for the Kubernetes-based offering. The protection boundary has moved from the logical partition level (which includes the operating system and application), to what is now the complete isolation of applications from the operating system. LEARN MORE ABOUT SECURING FINANCIAL TRANSACTIONS WITH HPVS Follow the link (or click the image below) to learn more about Confidential Computing for a financial transaction using HPVS. <a href=\"https://mediacenter.ibm.com/media/Confidential+Computing+for+a+financial+transaction+using+Hyper+Protect+Virtual+Server+for+VPC/1_vv3j2oo6\" target=\"_blank\">![](_attachments/module1_figure1.png){: loading=lazy width=\"400\"}</a> (IBM Media Center asset - 6 minutes runtime) As you progress through this section of the hands-on lab, you will be guided through the steps involved with configuring an HPVS instance on IBM Cloud. Afterwards, you will be provided the instructions needed to reproduce a simulated deployment of a fictitious PayNow application. This process will require the use of Git, Terraform, Hyper Protect \"Contracts\", and navigation of the IBM Cloud interface.","title":"IBM Cloud Hyper Protect Virtual Servers for Virtual Private Cloud"},{"location":"HPVS/01-Introduction-to-HPVS/#_2","text":"","title":""},{"location":"HPVS/01-Introduction-to-HPVS/#resources","text":"Additional HPVS resources that may be beneficial to seller and business partners are available: Sales Kit (Seismic) for HPVS Whitepaper (PDF): \"The Second Generation of IBM Hyper Protect Platform\"","title":"Resources"},{"location":"HPVS/01-Introduction-to-HPVS/#_3","text":"","title":""},{"location":"HPVS/01-Introduction-to-HPVS/#next-steps","text":"In the following section, you will need to review the pre-requisites and follow the provisioning instructions for setting up your IBM Cloud and local environments. Afterwards, IBM sellers and business partners will learn: How to configure and provision an HPVS instance on IBM Cloud How Contracts are needed to create an HPVS instance with the IBM Hyper Protect Container Runtime (HPCR) image How to deploy a sample application on HPVS COSTS Due to costs that potentially may be incurred from deploying a live HPVS instance on IBM Cloud\u2014 and because sellers and partners must use their own personal IBM Cloud accounts for previewing the IBM Cloud catalog \u2014it is recommended that those taking this course DO NOT deploy any HPVS instances for this Level 3 training, unless: You have a valid client opportunity number, in which case you may use that code to apply for a Hyper Protect Services \"Proof of Concept\" engagement \u2014 which will fund the demo environment for your client opportunity. Follow the procedures outlined HERE for how to apply. You have access to an IBM internal paid account for IBM Cloud, in which case billing will be charged to your respective IBM department, instead of your personal account. Follow the procedures outlined HERE for how to apply. You are willing to accept the charges to your personal IBM account and the credit card associated with that account. The IBM enablement team cannot reimburse such costs and any costs taken on by the IBM account are the responsibility of the user. In lieu of a live production environment, sellers will be furnished with the instruction sets necessary to reproduce these demonstrations as part of a funded client demonstration. Sales opportunity numbers can be applied towards Proof of Experience (PoX) engagements. Documentation for how to do so is included as a part of the coursework resources. IBM sellers and technical sellers , who are required to produce a Stand & Deliver recording of the hands-on demonstration as part of their accreditation process, you will NOT be required to show (on screen) anything beyond the initial configuration steps for Hyper Protect Virtual Servers for VPC on IBM Cloud. Do not deploy the instance, unless you are prepared to finance it on your personal IBM Cloud account. Furthermore, you are not required to record any of the steps involving the hypothetical PayNow application, as doing so would require deployment of a live instance. IBM business partners , who receive accreditation via a passing grade on a multiple-choice test, will only need to answer questions based on the initial configuration steps of Hyper Protect Virtual Servers for VPC on IBM Cloud. Quiz questions will not cover the screen readouts or other material involving either the PayNow application or a fully deployed instance. As mentioned previously, do not deploy the IBM Cloud instance into a live state unless you are prepared to self-finance any potential billing on your personal IBM Cloud account.","title":"Next steps"},{"location":"HPVS/02-Prerequites-and-Preparation/","text":"Prerequisites and Preparation The following module will guide you through the necessary setup and configuration required before deploying the HPVS lab environment. Sign up for an IBM Cloud account and IBMid using the following link: https://cloud.ibm.com/registration You will be asked to supply a credit card to be associated with the account. Any billing you accrue on your IBM Cloud account will be billed at the next IBM Cloud billing cycle to that credit card. If your IBM Cloud account requires an API key for login or belongs with a Federated account (most IBM employees), you will need to supply additional instructions for logging in via the IBM Cloud CLI. A quick way to look up the necessary login string (with a one-time passcode) for your account is to first use your web browser to log in to www.cloud.ibm.com . Once logged in, click on your user account icon in the top right-hand corner of the page and select Log in to CLI and API from the drop-down menu. A panel will open with a command line string that you can paste into your Terminal / PowerShell console for connecting via the IBM Cloud CLI. From the IBM Cloud web interface, provision a Lite plan of the IBM Log Analysis service from the following page: https://cloud.ibm.com/catalog/services/logdna?callback=%2Fobserve%2Flogging%2Fcreate Note that the \"Lite\" plan is free to use, but with limited functionality and only a 30 day window to operate before it is automatically de-provisioned. When configuring the service, use the following options: Service Name : Set to a unique name of your preference. Resource Group : Leave as default. Tags and Access Management tags can be left blank. Confirm that you have read and agree to the license agreements, then click Create to provision. You will need to record details about the Ingestion Host and the Ingestion ID for reference at a later step. They will be something similar to: Ingestion Host: syslog-a.eu-gb.logging.cloud.ibm.com Ingestion ID: 9a035a6ee2f2ae77c566a543e0957ed8 Locate the Host and ID specific to your environment by performing the following: Click Open Dashboard from the Log Analysis service page on IBM Cloud In the bottom-left corner of the dashboard, click the ? icon (for Install Instructions ). A panel to \"Add Log Sources\" will appear. From the left side of the panel, click to drill down into the rsyslog tab. In the top right of the page is a hidden string titled Your Ingestion key is: . Click the clipboard icon to the right of the string and save this value in your records as the Ingestion ID . In a large grey box on-screen are the contents for the /etc/rsyslog.d/22-logdna.conf file. Locate the two of lines towards the bottom which read: # Send messages to LogDNA over TCP using the template. *.* @@syslog-a.us-south.logging.cloud.ibm.com:6514;LogDNAFormat Your particular values will be different than the sample above. The second line is the one of interest to us at this time. Record YOUR unique values for the following segment: syslog-a.us-south.logging.cloud.ibm.com including everything between syslog and .com . Save this value in your records as the Ingestion Host . Install the Homebrew package manager on your local machine. Alternatively, Windows or Linux clients can use other package managers (like pip ) if you wish; however, be aware that the install commands and syntax may vary between package managers. If you do not have the Homebrew package manager installed in a macOS environment, execute the following instruction inside a Terminal console: /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" Follow the prompts until the installation has concluded, then continue with the lab guide instructions. Install the Docker container service by downloading the Docker Desktop version appropriate to your machine's operating system. Alternatively, use the brew package manager to install Docker on your local machine. This will be required for connecting to the IBM Cloud Container Registry. brew install docker Follow the prompts until the installation has concluded, then continue with the lab guide instructions. DOCKER DESKTOP MUST BE RUNNING After installation, ensure that the Docker Desktop service is running on your machine (check the taskbar or launch the application manually). Otherwise, you will encounter errors in Step 7 when trying to compile the PayNow container image. On your local desktop or laptop, download and install Git . Click to expand more details on how to configure Git for your particular operating system. macOS Open the macOS Terminal shell prompt. Execute the following instructions to install the Homebrew package manager: /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" Follow the instructions provided during the Homebrew installation to add Homebrew to your machine's local PATH. Once the installation of Homebrew is complete, execute the following command to install Git: brew install git After installation has concluded, verify the Git install using the following statement: git version Windows Visit the Git for Windows page and download the latest version to your machine. Once the installer has started, follow the instructions as provided in the Git Setup wizard screen until the installation is complete. Open the windows command prompt (or Git Bash if you selected not to use the standard Git Windows Command Prompt during the Git installation). Execute the following to verify Git was installed: git version Use Git to clone the HPVS \"PayNow\" demo code repository from GitHub. Enter the following command into Terminal to clone the repository via the command line: gh repo clone ibm-hyper-protect/paynow-website Alternatively, if you visit the GitHub repository, click the green Code button and then Download ZIP from the drop-down menu. This will download the GitHub repository code to a directory of your choosing on your local machine. The Pay Now Website is a simple application, that presents an interface to make payments. The application shows how sensitive payment related information (such as credit card data) is used. It is recommended to run this application in a confidential computing environment where PII data in use is protected from malicious actors. With Terminal, navigate to the paynow-website that you just cloned/saved locally on your machine in the previous step. For example: cd ~/Desktop/paynow-website Once inside the directory, execute the following command to build the PayNow container image for the linux/s390x platform and tag the container image: docker buildx build --platform linux/s390x -t us.icr.io/hpvs-sample/paynow-website . The container image build should take approximately 1 to 2 minutes to complete. Install the IBM Cloud Command Line Interface (CLI) for your local machine to manage resources in the IBM Cloud. Instructions for how to do so across a variety of operating systems are provided online: https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cli Create a public SSH key which will be used for connecting to the virtual server instance that we will deploy later. Within your IBM Cloud CLI or local Terminal command prompt, execute the following command to generate a public SSH key: ssh-keygen -t rsa The command will generate two files\u2014 id_rsa and id_rsa.pub \u2014which will be placed either under an .ssh directory (the exact directory address will be displayed to the command line, such as /Users/.ssh/id_rsa ) or within the same directory that you executed the ssh-key -t rsa instruction from. Execute the following instruction in the command line to open the current directory with your desktop file browser and look for the pair of key files: open . SAVE this .pub file where you can easily retrieve it, as it will be necessary at a later stage. Next, install the IBM Cloud Code Engine plug-in: ibmcloud plugin install code-engine DEPRECATION OF IBM CLOUD FOUNDRY ( CF ) IBM Cloud Foundry or CF has been deprecated as of June 1, 2023 . If you encounter any IBM Cloud documentation requiring the use of CF , substitute commands using the Code Engine API documentation in its place. Execute the following command to verify that the plug-in is installed: ibmcloud plugin show code-engine Log in to the IBM Cloud Container Registry with the following command: ibmcloud cr login --client docker CONNECTION ERROR If you are unable to connect to the IBM Cloud Container Registry and receive an error similar to the following... Failed to 'docker login' to 'us.icr.io' with error: Error saving credentials: error storing credentials... You will need to remove an existing Docker configuration file from your local machine first. Do so with the following command: rm ~/.docker/config.json Afterwards, try to connect to the IBM Cloud Container Registry again using the same command as before. Create a namespace and push the container image by running the following commands. Execute these in the SAME directory that you saved your paynow-website clone in Step 6 and built your Docker container image in Step 7. ibmcloud cr namespace-add hpvs-sample docker push us.icr.io/hpvs-sample/paynow-website Wait until all of the components have successfully been pushed to the IBM Cloud repository. Once complete, the Terminal console will report back with a RepoDigests value. COPY this value to a clipboard and save it for reference later. If you need to retrieve the digest value at a later time, you can do so by executing the following command. Do so now and also record the FULL print-out to a notepad. The information on your container registry will be useful at a later stage. docker inspect us.icr.io/hpvs-sample/paynow-website | grep -A 1 RepoDigests Next Steps At this stage, the PayNow application's container image has been prepared and is now available for use in the IBM Cloud. In the following section, you will use these tools and technologies to generate a Contract for creation of an HPVS instance with the IBM Hyper Protect Container Runtime (HPCR) image.","title":"Prerequisites and Preparation"},{"location":"HPVS/02-Prerequites-and-Preparation/#prerequisites-and-preparation","text":"The following module will guide you through the necessary setup and configuration required before deploying the HPVS lab environment. Sign up for an IBM Cloud account and IBMid using the following link: https://cloud.ibm.com/registration You will be asked to supply a credit card to be associated with the account. Any billing you accrue on your IBM Cloud account will be billed at the next IBM Cloud billing cycle to that credit card. If your IBM Cloud account requires an API key for login or belongs with a Federated account (most IBM employees), you will need to supply additional instructions for logging in via the IBM Cloud CLI. A quick way to look up the necessary login string (with a one-time passcode) for your account is to first use your web browser to log in to www.cloud.ibm.com . Once logged in, click on your user account icon in the top right-hand corner of the page and select Log in to CLI and API from the drop-down menu. A panel will open with a command line string that you can paste into your Terminal / PowerShell console for connecting via the IBM Cloud CLI. From the IBM Cloud web interface, provision a Lite plan of the IBM Log Analysis service from the following page: https://cloud.ibm.com/catalog/services/logdna?callback=%2Fobserve%2Flogging%2Fcreate Note that the \"Lite\" plan is free to use, but with limited functionality and only a 30 day window to operate before it is automatically de-provisioned. When configuring the service, use the following options: Service Name : Set to a unique name of your preference. Resource Group : Leave as default. Tags and Access Management tags can be left blank. Confirm that you have read and agree to the license agreements, then click Create to provision. You will need to record details about the Ingestion Host and the Ingestion ID for reference at a later step. They will be something similar to: Ingestion Host: syslog-a.eu-gb.logging.cloud.ibm.com Ingestion ID: 9a035a6ee2f2ae77c566a543e0957ed8 Locate the Host and ID specific to your environment by performing the following: Click Open Dashboard from the Log Analysis service page on IBM Cloud In the bottom-left corner of the dashboard, click the ? icon (for Install Instructions ). A panel to \"Add Log Sources\" will appear. From the left side of the panel, click to drill down into the rsyslog tab. In the top right of the page is a hidden string titled Your Ingestion key is: . Click the clipboard icon to the right of the string and save this value in your records as the Ingestion ID . In a large grey box on-screen are the contents for the /etc/rsyslog.d/22-logdna.conf file. Locate the two of lines towards the bottom which read: # Send messages to LogDNA over TCP using the template. *.* @@syslog-a.us-south.logging.cloud.ibm.com:6514;LogDNAFormat Your particular values will be different than the sample above. The second line is the one of interest to us at this time. Record YOUR unique values for the following segment: syslog-a.us-south.logging.cloud.ibm.com including everything between syslog and .com . Save this value in your records as the Ingestion Host . Install the Homebrew package manager on your local machine. Alternatively, Windows or Linux clients can use other package managers (like pip ) if you wish; however, be aware that the install commands and syntax may vary between package managers. If you do not have the Homebrew package manager installed in a macOS environment, execute the following instruction inside a Terminal console: /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" Follow the prompts until the installation has concluded, then continue with the lab guide instructions. Install the Docker container service by downloading the Docker Desktop version appropriate to your machine's operating system. Alternatively, use the brew package manager to install Docker on your local machine. This will be required for connecting to the IBM Cloud Container Registry. brew install docker Follow the prompts until the installation has concluded, then continue with the lab guide instructions. DOCKER DESKTOP MUST BE RUNNING After installation, ensure that the Docker Desktop service is running on your machine (check the taskbar or launch the application manually). Otherwise, you will encounter errors in Step 7 when trying to compile the PayNow container image. On your local desktop or laptop, download and install Git . Click to expand more details on how to configure Git for your particular operating system. macOS Open the macOS Terminal shell prompt. Execute the following instructions to install the Homebrew package manager: /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" Follow the instructions provided during the Homebrew installation to add Homebrew to your machine's local PATH. Once the installation of Homebrew is complete, execute the following command to install Git: brew install git After installation has concluded, verify the Git install using the following statement: git version Windows Visit the Git for Windows page and download the latest version to your machine. Once the installer has started, follow the instructions as provided in the Git Setup wizard screen until the installation is complete. Open the windows command prompt (or Git Bash if you selected not to use the standard Git Windows Command Prompt during the Git installation). Execute the following to verify Git was installed: git version Use Git to clone the HPVS \"PayNow\" demo code repository from GitHub. Enter the following command into Terminal to clone the repository via the command line: gh repo clone ibm-hyper-protect/paynow-website Alternatively, if you visit the GitHub repository, click the green Code button and then Download ZIP from the drop-down menu. This will download the GitHub repository code to a directory of your choosing on your local machine. The Pay Now Website is a simple application, that presents an interface to make payments. The application shows how sensitive payment related information (such as credit card data) is used. It is recommended to run this application in a confidential computing environment where PII data in use is protected from malicious actors. With Terminal, navigate to the paynow-website that you just cloned/saved locally on your machine in the previous step. For example: cd ~/Desktop/paynow-website Once inside the directory, execute the following command to build the PayNow container image for the linux/s390x platform and tag the container image: docker buildx build --platform linux/s390x -t us.icr.io/hpvs-sample/paynow-website . The container image build should take approximately 1 to 2 minutes to complete. Install the IBM Cloud Command Line Interface (CLI) for your local machine to manage resources in the IBM Cloud. Instructions for how to do so across a variety of operating systems are provided online: https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cli Create a public SSH key which will be used for connecting to the virtual server instance that we will deploy later. Within your IBM Cloud CLI or local Terminal command prompt, execute the following command to generate a public SSH key: ssh-keygen -t rsa The command will generate two files\u2014 id_rsa and id_rsa.pub \u2014which will be placed either under an .ssh directory (the exact directory address will be displayed to the command line, such as /Users/.ssh/id_rsa ) or within the same directory that you executed the ssh-key -t rsa instruction from. Execute the following instruction in the command line to open the current directory with your desktop file browser and look for the pair of key files: open . SAVE this .pub file where you can easily retrieve it, as it will be necessary at a later stage. Next, install the IBM Cloud Code Engine plug-in: ibmcloud plugin install code-engine DEPRECATION OF IBM CLOUD FOUNDRY ( CF ) IBM Cloud Foundry or CF has been deprecated as of June 1, 2023 . If you encounter any IBM Cloud documentation requiring the use of CF , substitute commands using the Code Engine API documentation in its place. Execute the following command to verify that the plug-in is installed: ibmcloud plugin show code-engine Log in to the IBM Cloud Container Registry with the following command: ibmcloud cr login --client docker CONNECTION ERROR If you are unable to connect to the IBM Cloud Container Registry and receive an error similar to the following... Failed to 'docker login' to 'us.icr.io' with error: Error saving credentials: error storing credentials... You will need to remove an existing Docker configuration file from your local machine first. Do so with the following command: rm ~/.docker/config.json Afterwards, try to connect to the IBM Cloud Container Registry again using the same command as before. Create a namespace and push the container image by running the following commands. Execute these in the SAME directory that you saved your paynow-website clone in Step 6 and built your Docker container image in Step 7. ibmcloud cr namespace-add hpvs-sample docker push us.icr.io/hpvs-sample/paynow-website Wait until all of the components have successfully been pushed to the IBM Cloud repository. Once complete, the Terminal console will report back with a RepoDigests value. COPY this value to a clipboard and save it for reference later. If you need to retrieve the digest value at a later time, you can do so by executing the following command. Do so now and also record the FULL print-out to a notepad. The information on your container registry will be useful at a later stage. docker inspect us.icr.io/hpvs-sample/paynow-website | grep -A 1 RepoDigests","title":"Prerequisites and Preparation"},{"location":"HPVS/02-Prerequites-and-Preparation/#_1","text":"","title":""},{"location":"HPVS/02-Prerequites-and-Preparation/#next-steps","text":"At this stage, the PayNow application's container image has been prepared and is now available for use in the IBM Cloud. In the following section, you will use these tools and technologies to generate a Contract for creation of an HPVS instance with the IBM Hyper Protect Container Runtime (HPCR) image.","title":"Next Steps"},{"location":"HPVS/03-Contract-Creation/","text":"Creation of a Contract for PayNow Application via Terraform In this module, you will use these tools and technologies to generate a Contract for creation of an HPVS instance with the IBM Hyper Protect Container Runtime (HPCR) image. Install the OpenSSL binary on your local machine. More information about the OpenSSL Project can be found within their online documentation: https://www.openssl.org To install OpenSSL, either read the instructions detailed here ( https://www.openssl.org/source/gitrepo.html ) or execute the following commands one at a time in your command line interface: git clone git://git.openssl.org/openssl.git cd openssl git config core.autocrlf false git config core.eol lf git checkout . Install the Terraform CLI on your local machine. Detailed instructions and video instructions for doing so are provided online: https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli You may either follow the detailed instructions (above) or execute the condensed instructions line-by-line (below): brew tap hashicorp/tap brew install hashicorp/tap/terraform brew update brew upgrade hashicorp/tap/terraform terraform -version Now you are ready to create the Contract . Use Git to clone the following repository to your local machine ( note: this is a different repository to the one you cloned previously ): gh repo clone ibm-hyper-protect/linuxone-vsi-automation-samples Alternatively, you can Download ZIP the file manually from the GitHub repository using your web browser. Navigate to the following directory: cd linuxone-vsi-automation-samples/terraform-hpvs/create-contract-dynamic-registry/ Edit the docker-compose.yml file in the /compose folder. You need to specify YOUR container image digest ( Step 12 of the previous module) and set the exposed ports to the following. Delete any other lines that were included in the original YAML file by default. Replicate the following example of a completed docker-compose.yml file. On Line 4 for the argument image: , replace the last <sha256> characters with your container image digest: 1 2 3 4 5 6 7 version : \"3\" services : paynow : image : ${REGISTRY}/hpvs-sample/paynow-website@sha256:<sha256> ports : - \"8080:8080\" - \"8443:8443\" Be careful to match the indentation and whitespacing exactly as given below, as YAML files use indentation to parse instructions. When satisfied, save the changes and exit the file. Return to the linuxone-vsi-automation-samples/terraform-hpvs/create-contract-dynamic-registry/ directory from Step 4. Locate the my-settings.auto.tfvars-template file within this directory. Duplicate this file and then rename it to my-settings.auto.tfvars instead. Edit the my-settings.auto.tfvars file and replicate (using YOUR IBM Cloud account details) the following example as closely as possible: 1 2 3 4 5 registry=\"<your container registry>\" pull_username=\"iamapikey\" pull_password=\"<your API key>\" logdna_ingestion_key=\"<your ingestion key>\" logdna_ingestion_hostname=\"<your ingestion host>\" Adjust the following values: Line 1 : Replace <your container registry> with the first component of the container registry digest you recorded in Step 13 of the Prerequisites module. Likely this is a value such as us.icr.io Preserve the double-quotation marks. Line 3 : Replace <your API key> with the contents of the key.pub SSH key that you created and stored locally in Step 8 of the Prerequisites module. Preserve the double-quotation marks. Line 4 : Replace <your ingestion key> with the Ingestion Key recorded in Step 2 of the Prerequisites module. This is likely a value similar to a17b8b912bcddda9d84d544d82a74c50 . Preserve the double-quotation marks. Line 5 : Replace <your ingestion host> with the Ingestion Host recorded in Step 2 of the Prerequisites module. This is likely a value similar to syslog-a.us-south.logging.cloud.ibm.com . Preserve the double-quotation marks. When satisfied, save the changes and exit the file. To initialize Terraform, execute the following command: terraform init Generate the Terraform Contract using the following command: terraform apply You will be prompted mid-way through the process whether you want Terraform to perform the actions prescribed, to which you should respond with yes and hit the Return key. Once completed, you should see the following screen: Display the Contract that is created with the Terraform script by running the following: cat build/contract.yml RECORD the entirety of the contract to a notepad. You will need to reference this information in the following module. Next Steps In the following section, you will configure and deploy a Hyper Protect Virtual Servers for VPC instance on IBM Cloud using the freshly generated Contract .","title":"Creation of a Contract for PayNow Application via Terraform"},{"location":"HPVS/03-Contract-Creation/#creation-of-a-contract-for-paynow-application-via-terraform","text":"In this module, you will use these tools and technologies to generate a Contract for creation of an HPVS instance with the IBM Hyper Protect Container Runtime (HPCR) image. Install the OpenSSL binary on your local machine. More information about the OpenSSL Project can be found within their online documentation: https://www.openssl.org To install OpenSSL, either read the instructions detailed here ( https://www.openssl.org/source/gitrepo.html ) or execute the following commands one at a time in your command line interface: git clone git://git.openssl.org/openssl.git cd openssl git config core.autocrlf false git config core.eol lf git checkout . Install the Terraform CLI on your local machine. Detailed instructions and video instructions for doing so are provided online: https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli You may either follow the detailed instructions (above) or execute the condensed instructions line-by-line (below): brew tap hashicorp/tap brew install hashicorp/tap/terraform brew update brew upgrade hashicorp/tap/terraform terraform -version Now you are ready to create the Contract . Use Git to clone the following repository to your local machine ( note: this is a different repository to the one you cloned previously ): gh repo clone ibm-hyper-protect/linuxone-vsi-automation-samples Alternatively, you can Download ZIP the file manually from the GitHub repository using your web browser. Navigate to the following directory: cd linuxone-vsi-automation-samples/terraform-hpvs/create-contract-dynamic-registry/ Edit the docker-compose.yml file in the /compose folder. You need to specify YOUR container image digest ( Step 12 of the previous module) and set the exposed ports to the following. Delete any other lines that were included in the original YAML file by default. Replicate the following example of a completed docker-compose.yml file. On Line 4 for the argument image: , replace the last <sha256> characters with your container image digest: 1 2 3 4 5 6 7 version : \"3\" services : paynow : image : ${REGISTRY}/hpvs-sample/paynow-website@sha256:<sha256> ports : - \"8080:8080\" - \"8443:8443\" Be careful to match the indentation and whitespacing exactly as given below, as YAML files use indentation to parse instructions. When satisfied, save the changes and exit the file. Return to the linuxone-vsi-automation-samples/terraform-hpvs/create-contract-dynamic-registry/ directory from Step 4. Locate the my-settings.auto.tfvars-template file within this directory. Duplicate this file and then rename it to my-settings.auto.tfvars instead. Edit the my-settings.auto.tfvars file and replicate (using YOUR IBM Cloud account details) the following example as closely as possible: 1 2 3 4 5 registry=\"<your container registry>\" pull_username=\"iamapikey\" pull_password=\"<your API key>\" logdna_ingestion_key=\"<your ingestion key>\" logdna_ingestion_hostname=\"<your ingestion host>\" Adjust the following values: Line 1 : Replace <your container registry> with the first component of the container registry digest you recorded in Step 13 of the Prerequisites module. Likely this is a value such as us.icr.io Preserve the double-quotation marks. Line 3 : Replace <your API key> with the contents of the key.pub SSH key that you created and stored locally in Step 8 of the Prerequisites module. Preserve the double-quotation marks. Line 4 : Replace <your ingestion key> with the Ingestion Key recorded in Step 2 of the Prerequisites module. This is likely a value similar to a17b8b912bcddda9d84d544d82a74c50 . Preserve the double-quotation marks. Line 5 : Replace <your ingestion host> with the Ingestion Host recorded in Step 2 of the Prerequisites module. This is likely a value similar to syslog-a.us-south.logging.cloud.ibm.com . Preserve the double-quotation marks. When satisfied, save the changes and exit the file. To initialize Terraform, execute the following command: terraform init Generate the Terraform Contract using the following command: terraform apply You will be prompted mid-way through the process whether you want Terraform to perform the actions prescribed, to which you should respond with yes and hit the Return key. Once completed, you should see the following screen: Display the Contract that is created with the Terraform script by running the following: cat build/contract.yml RECORD the entirety of the contract to a notepad. You will need to reference this information in the following module.","title":"Creation of a Contract for PayNow Application via Terraform"},{"location":"HPVS/03-Contract-Creation/#_1","text":"","title":""},{"location":"HPVS/03-Contract-Creation/#next-steps","text":"In the following section, you will configure and deploy a Hyper Protect Virtual Servers for VPC instance on IBM Cloud using the freshly generated Contract .","title":"Next Steps"},{"location":"HPVS/04-Configure-HPVS/","text":"Configuration of a Hyper Protect Virtual Servers for VPC Instance on IBM Cloud WATCH THIS DEMONSTRATION Peter Szmrecsanyi (IBM Hyper Protect Services - Solution Architect for zCAT) demonstrates how to configure and deploy a Hyper Protect Virtual Servers for VPC instance on IBM Cloud, using the Contract generated in the previous module. From the IBM Cloud dashboard, click the stack icon in the top-left corner of the interface to expand the drop-down menu options. From the left-side menu, drill down into VPC Infrastructure > Compute > Virtual Server Instances . Once the details page for Virtual Server Instances for VPC has loaded, select the Create + blue icon near the top-right corner of the interface. This will redirect the web browser to the configuration screen. The instructions that follow will guide you, top to bottom, across each of the configuration fields available for Virtual Server Instances for VPC . IBM CLOUD IS CONTINUOUSLY UPDATING Be aware that the IBM Cloud interface is continuously evolving and updating; it may be the case that the order of these options, or the exact specifications/fields that they offer, may differ slightly from the lab guide instructions or accompanying video recordings. SERVER TYPE Specify the architecture for your VPC instance. Select the option for IBM Z, LinuxONE . CONFIDENTIAL COMPUTING Switch this to ON . Note that the Confidential Compute option on the configuration page is only available when selecting a Z/LinuxONE architecture. If you change the Server Type to a different (non-IBM Systems) type of architecture, the Confidential Compute option is unavailable. LOCATION Select the location in which you wish the VPC instance to be deployed. DETAILS Provide a name for your VPC (for example, paynow-demo ) and a resource group (any resource group to which your account belongs is acceptable). IMAGE AND PROFILE Image should be set automatically to Hyper Protect . This is a result of our activation of the Confidential Computing option earlier in the configuration steps. Click the Change Image button to the right of the table to specify which version of IBM Hyper Protect that you wish to utilize for this deployment. At the time of publishing, there are two options (version 10 and 11) available. Version 10 supports Docker containerization, whilst Version 11 supports Podman containers. It is recommended that you use the latest Image version (11 or higher). Profile should be set to Balanced and can be adjusted by clicking the Change Profile button to the right of the table. By default, Profile will automatically be configured for \"Balanced\", which corresponds to the lowest-cost (but also lowest-performing) configuration of the VPC Profile. If a real-world demonstration of this technology requires additional vPCUs, memory, bandwidth, and so on, then it is recommend that you increase the Profile value as appropriate. Higher-tier Profiles are available from the drop-down menu and come at greater cost compared to the default (\"Balanced\") configuration. SSH KEYS SSH keys are optional for every VPC deployment, and in the case of this lab they are NOT required. Leave this field as blank. STORAGE Boot Volume : Leave as the default recommendation. Users have the option to supply their own storage as a boot volume if they wish, but it is NOT required for this lab. Data Volumes : By default, this table is empty for most users \u2014 and because data volumes are NOT required for the purposes of this lab, you may ignore this field. NETWORKING A default virtual private cloud network will be generated by IBM Cloud automatically. You may keep the existing network (recommended) or create one of your own. NETWORK INTERFACES A network interface is automatically defined by IBM Cloud. It is recommended that you use the default value, rather than define one yourself. ADVANCED OPTIONS User Data : click on the title / box to expand the options available to you. This is the field into which you must supply the Terraform-generated Contract that was created earlier. You may either copy and paste the contract details directly into the text field, or upload a Contract document from your desktop. At this stage, the VPC has been fully configured and could potentially be deployed into a live environment. Beyond this point, your personal IBM account and credit card WILL BE BILLED \u2014 unless you are willing to accrue and pay these charges, you should back out now from the configuration screen on IBM Cloud. COSTS Due to costs that potentially may be incurred from deploying a live VPC or HPVS instance on IBM Cloud\u2014 and because sellers and partners must use their own personal IBM Cloud accounts for previewing the IBM Cloud catalog \u2014it is recommended that those taking this course DO NOT deploy any HPVS instances for this Level 3 training, unless: You have a valid client opportunity number, in which case you may use that code to apply for a Hyper Protect Services \"Proof of Concept\" engagement \u2014 which will fund the demo environment for your client opportunity. Follow the procedures outlined HERE for how to apply. You have access to an IBM internal paid account for IBM Cloud, in which case billing will be charged to your respective IBM department, instead of your personal account. Follow the procedures outlined HERE for how to apply. You are willing to accept the charges to your personal IBM account and the credit card associated with that account. The IBM enablement team cannot reimburse such costs and any costs taken on by the IBM account are the responsibility of the user. IBM sellers and technical sellers , who are required to produce a Stand & Deliver recording of the hands-on demonstration as part of their accreditation process, you will NOT be required to show (on screen) anything beyond the initial configuration steps for Hyper Protect Virtual Servers for VPC on IBM Cloud. Do not deploy the instance, unless you are prepared to finance it on your personal IBM Cloud account. Furthermore, you are not required to record any of the steps involving the hypothetical PayNow application, as doing so would require deployment of a live instance. IBM business partners , who receive accreditation via a passing grade on a multiple-choice test, will only need to answer questions based on the initial configuration steps of Hyper Protect Virtual Servers for VPC on IBM Cloud. Quiz questions will not cover the screen readouts or other material involving either the PayNow application or a fully deployed instance. As mentioned previously, do not deploy the IBM Cloud instance into a live state unless you are prepared to self-finance any potential billing on your personal IBM Cloud account. Optional : It is recommended that you follow along and read the instructions given below. But due to the potential cost obligations, it is not required that you perform these tasks yourself \u2014 unless you are willing to incur the expenses to your personal IBM Cloud account. If you do create an instance (using the Create Virtual Server button) at this point, the IBM Cloud dashboard will automatically redirect back to the Virtual Server Instances for VPC dashboard, where you can watch the progress of the VPC instance as it provisions. To track the progress of the deployment in further detail, look along the far right side of the provisioning VPC instance for an icon resembling three vertically stacked dots. Click that icon to open up a drop-down menu and select the Open Serial Console button from the options. After the Serial Console has loaded, wait for the console terminal output to read \"Configuring logging...\" and \"Sending logging probe to...\" , similar to the messages captured in the following screenshot. Once those messages (or something quite similar \u2014 the variables for your particular instance may vary) the provisioning of the VPC instance is complete. Return to the Virtual Server Instances for VPC dashboard on the IBM Cloud page. Click the name of the deployed paynow-demo instance from the table to drill down into the instance details. Once the details panel has finished loading, scroll down to the bottom of the page and locate the Network Interfaces section. A single interface should be listed, corresponding to the default subnet that was selected in the Networking section of the IBM Cloud configuration steps that were performed earlier. On the far-right side of the table entry, click the Edit (pencil) icon to pull open an Edit Network Interface panel. Within the Floating IP Address field, change the value to Reserve a new floating IP . Once satisfied, click Save and the details panel will close. Notice that the IBM Cloud dashboard will refresh and a new Floating IP Address is now assigned to the Network Interfaces section. Now you are ready to examine the PayNow application user interface. Copy the Floating IP Address from the Network Interfaces section. Open a new web browser and into the address field enter: https://FLOATING_IP_ADDRESS:8443 ADDRESS AND PORT Note that :8443 denotes the port address of the PayNow application. Replace the FLOATING_IP_ADDRESS characters with the value unique to your environment. WARNING You may receive a warning error about a Potential Security Risk Ahead , an Unsecured Website , or so on. You can safely ignore this error and proceed to the web page. Your web browser will now open to the hosted PayNow application web portal.","title":"Configuration of a Hyper Protect Virtual Servers for VPC Instance on IBM Cloud"},{"location":"HPVS/04-Configure-HPVS/#configuration-of-a-hyper-protect-virtual-servers-for-vpc-instance-on-ibm-cloud","text":"WATCH THIS DEMONSTRATION Peter Szmrecsanyi (IBM Hyper Protect Services - Solution Architect for zCAT) demonstrates how to configure and deploy a Hyper Protect Virtual Servers for VPC instance on IBM Cloud, using the Contract generated in the previous module. From the IBM Cloud dashboard, click the stack icon in the top-left corner of the interface to expand the drop-down menu options. From the left-side menu, drill down into VPC Infrastructure > Compute > Virtual Server Instances . Once the details page for Virtual Server Instances for VPC has loaded, select the Create + blue icon near the top-right corner of the interface. This will redirect the web browser to the configuration screen. The instructions that follow will guide you, top to bottom, across each of the configuration fields available for Virtual Server Instances for VPC . IBM CLOUD IS CONTINUOUSLY UPDATING Be aware that the IBM Cloud interface is continuously evolving and updating; it may be the case that the order of these options, or the exact specifications/fields that they offer, may differ slightly from the lab guide instructions or accompanying video recordings. SERVER TYPE Specify the architecture for your VPC instance. Select the option for IBM Z, LinuxONE . CONFIDENTIAL COMPUTING Switch this to ON . Note that the Confidential Compute option on the configuration page is only available when selecting a Z/LinuxONE architecture. If you change the Server Type to a different (non-IBM Systems) type of architecture, the Confidential Compute option is unavailable. LOCATION Select the location in which you wish the VPC instance to be deployed. DETAILS Provide a name for your VPC (for example, paynow-demo ) and a resource group (any resource group to which your account belongs is acceptable). IMAGE AND PROFILE Image should be set automatically to Hyper Protect . This is a result of our activation of the Confidential Computing option earlier in the configuration steps. Click the Change Image button to the right of the table to specify which version of IBM Hyper Protect that you wish to utilize for this deployment. At the time of publishing, there are two options (version 10 and 11) available. Version 10 supports Docker containerization, whilst Version 11 supports Podman containers. It is recommended that you use the latest Image version (11 or higher). Profile should be set to Balanced and can be adjusted by clicking the Change Profile button to the right of the table. By default, Profile will automatically be configured for \"Balanced\", which corresponds to the lowest-cost (but also lowest-performing) configuration of the VPC Profile. If a real-world demonstration of this technology requires additional vPCUs, memory, bandwidth, and so on, then it is recommend that you increase the Profile value as appropriate. Higher-tier Profiles are available from the drop-down menu and come at greater cost compared to the default (\"Balanced\") configuration. SSH KEYS SSH keys are optional for every VPC deployment, and in the case of this lab they are NOT required. Leave this field as blank. STORAGE Boot Volume : Leave as the default recommendation. Users have the option to supply their own storage as a boot volume if they wish, but it is NOT required for this lab. Data Volumes : By default, this table is empty for most users \u2014 and because data volumes are NOT required for the purposes of this lab, you may ignore this field. NETWORKING A default virtual private cloud network will be generated by IBM Cloud automatically. You may keep the existing network (recommended) or create one of your own. NETWORK INTERFACES A network interface is automatically defined by IBM Cloud. It is recommended that you use the default value, rather than define one yourself. ADVANCED OPTIONS User Data : click on the title / box to expand the options available to you. This is the field into which you must supply the Terraform-generated Contract that was created earlier. You may either copy and paste the contract details directly into the text field, or upload a Contract document from your desktop. At this stage, the VPC has been fully configured and could potentially be deployed into a live environment. Beyond this point, your personal IBM account and credit card WILL BE BILLED \u2014 unless you are willing to accrue and pay these charges, you should back out now from the configuration screen on IBM Cloud. COSTS Due to costs that potentially may be incurred from deploying a live VPC or HPVS instance on IBM Cloud\u2014 and because sellers and partners must use their own personal IBM Cloud accounts for previewing the IBM Cloud catalog \u2014it is recommended that those taking this course DO NOT deploy any HPVS instances for this Level 3 training, unless: You have a valid client opportunity number, in which case you may use that code to apply for a Hyper Protect Services \"Proof of Concept\" engagement \u2014 which will fund the demo environment for your client opportunity. Follow the procedures outlined HERE for how to apply. You have access to an IBM internal paid account for IBM Cloud, in which case billing will be charged to your respective IBM department, instead of your personal account. Follow the procedures outlined HERE for how to apply. You are willing to accept the charges to your personal IBM account and the credit card associated with that account. The IBM enablement team cannot reimburse such costs and any costs taken on by the IBM account are the responsibility of the user. IBM sellers and technical sellers , who are required to produce a Stand & Deliver recording of the hands-on demonstration as part of their accreditation process, you will NOT be required to show (on screen) anything beyond the initial configuration steps for Hyper Protect Virtual Servers for VPC on IBM Cloud. Do not deploy the instance, unless you are prepared to finance it on your personal IBM Cloud account. Furthermore, you are not required to record any of the steps involving the hypothetical PayNow application, as doing so would require deployment of a live instance. IBM business partners , who receive accreditation via a passing grade on a multiple-choice test, will only need to answer questions based on the initial configuration steps of Hyper Protect Virtual Servers for VPC on IBM Cloud. Quiz questions will not cover the screen readouts or other material involving either the PayNow application or a fully deployed instance. As mentioned previously, do not deploy the IBM Cloud instance into a live state unless you are prepared to self-finance any potential billing on your personal IBM Cloud account.","title":"Configuration of a Hyper Protect Virtual Servers for VPC Instance on IBM Cloud"},{"location":"HPVS/04-Configure-HPVS/#_1","text":"","title":""},{"location":"HPVS/04-Configure-HPVS/#optional-it-is-recommended-that-you-follow-along-and-read-the-instructions-given-below-but-due-to-the-potential-cost-obligations-it-is-not-required-that-you-perform-these-tasks-yourself-unless-you-are-willing-to-incur-the-expenses-to-your-personal-ibm-cloud-account","text":"If you do create an instance (using the Create Virtual Server button) at this point, the IBM Cloud dashboard will automatically redirect back to the Virtual Server Instances for VPC dashboard, where you can watch the progress of the VPC instance as it provisions. To track the progress of the deployment in further detail, look along the far right side of the provisioning VPC instance for an icon resembling three vertically stacked dots. Click that icon to open up a drop-down menu and select the Open Serial Console button from the options. After the Serial Console has loaded, wait for the console terminal output to read \"Configuring logging...\" and \"Sending logging probe to...\" , similar to the messages captured in the following screenshot. Once those messages (or something quite similar \u2014 the variables for your particular instance may vary) the provisioning of the VPC instance is complete. Return to the Virtual Server Instances for VPC dashboard on the IBM Cloud page. Click the name of the deployed paynow-demo instance from the table to drill down into the instance details. Once the details panel has finished loading, scroll down to the bottom of the page and locate the Network Interfaces section. A single interface should be listed, corresponding to the default subnet that was selected in the Networking section of the IBM Cloud configuration steps that were performed earlier. On the far-right side of the table entry, click the Edit (pencil) icon to pull open an Edit Network Interface panel. Within the Floating IP Address field, change the value to Reserve a new floating IP . Once satisfied, click Save and the details panel will close. Notice that the IBM Cloud dashboard will refresh and a new Floating IP Address is now assigned to the Network Interfaces section. Now you are ready to examine the PayNow application user interface. Copy the Floating IP Address from the Network Interfaces section. Open a new web browser and into the address field enter: https://FLOATING_IP_ADDRESS:8443 ADDRESS AND PORT Note that :8443 denotes the port address of the PayNow application. Replace the FLOATING_IP_ADDRESS characters with the value unique to your environment. WARNING You may receive a warning error about a Potential Security Risk Ahead , an Unsecured Website , or so on. You can safely ignore this error and proceed to the web page. Your web browser will now open to the hosted PayNow application web portal.","title":"Optional: It is recommended that you follow along and read the instructions given below. But due to the potential cost obligations, it is not required that you perform these tasks yourself \u2014 unless you are willing to incur the expenses to your personal IBM Cloud account."}]}